{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dev_interaction_util import *\n",
    "from DevCvAnalysis import DevCvAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.yml\") \n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thhe point of the intervention only analysis is that we have already done the intervention analysis in an R linear model. We should be able to reproduce that result here. So if we don't, we can work on debugging what might be wrong with the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from InterventionCVManager import *\n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n",
    "\n",
    "icvm = InterventionCVManager(dropbox_data_dir)\n",
    "#icvm.mode = 'full_pipeline_test'\n",
    "icvm.mode = 'fast_analysis'\n",
    "#icvm.mode = 'full_analysis'\n",
    "\n",
    "#dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV022', 'DEV002', 'DEV280', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "run_real_analysis is True, so we're not randomizing the outcomes. \n",
      "(243, 33)\n",
      "(243, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict change"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sets of variables to run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up a function that loops runs the scoring loop above (which does one cross-validation analysis), and the nadditionally:\n",
    "- selects the best model based on the overall results\n",
    "- Runs a final fit\n",
    "- presents model results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include functions that compare models with and without individual differences and interactions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should manually verify that in the following list, the intervention_group allocations are randomized (if we're running a test run) or that they are accurate (if it's not a test run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>intervention_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV004</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV008</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID intervention_group\n",
       "0    DEV004             umpqua\n",
       "1    DEV005             umpqua\n",
       "2    DEV008             umpqua\n",
       "3    DEV009             umpqua\n",
       "4    DEV010           mckenzie\n",
       "..      ...                ...\n",
       "238  DEV308         willamette\n",
       "239  DEV309             umpqua\n",
       "240  DEV310           mckenzie\n",
       "241  DEV311         willamette\n",
       "242  DEV312           mckenzie\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    dev_cv_analysis.outcome_measures['SID'],\n",
    "      dev_cv_analysis.group_assignments\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SID', 'bf', 'NUTRIENT_RICH_FOODS_INDEX_2wkAverage',\n",
       "       'ANTINUTRIENT_DENSITY_2wkAverage', 'total_calorie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_cv_analysis.outcome_measures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = dev_cv_analysis.group_assignment_onehots.columns.tolist()\n",
    "inddiff_cols = dev_cv_analysis.get_predictors_main_names()\n",
    "\n",
    "interaction_cols = [id + \"*\" + cond for id in inddiff_cols for cond in condition_cols]\n",
    "\n",
    "predictor_sets = {\n",
    "    'condition_only': condition_cols\n",
    "}\n",
    "\n",
    "\n",
    "outcome_vars_to_try = [ 'bf','cancer_promoting_FFQ',\n",
    "       'NUTRIENT_DENSITY_2wkAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDM, BIS_11, PCS, ACES_sum, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, NCS_total, TESQ_E_sum, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, cancer_promoting_minus_preventing_FCI, age365, education_own, household_income_per_person, SST_PostErrorSlowW1_mean, SST_mean_ssrt_0, ROC_Crave_Regulate_Minus_Look, ROC_Crave_Minus_Neutral, WTP_unhealthy_minus_healthy, wtp_liked_value_association-test_z_FDR_0.01, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01, roc_reappraiseCrave_multivariate_regulation, sst_CorrectGo_striatum_joint_mask, sst_FailedStop_motor_control_striatum_joint_mask, sst_CorrectGoFollowingFailedStop_striatum_joint_mask, Planning_aggregate, Restraint_aggregate, IMI_effort_importance_aggregate, wtp_roc_koban_kober_craving_combined, birthsex_factor_Male, umpqua, mckenzie, EDM*umpqua, BIS_11*umpqua, PCS*umpqua, ACES_sum*umpqua, BFI_agreeableness*umpqua, BFI_conscientiousness*umpqua, BFI_extraversion*umpqua, BFI_neuroticism*umpqua, BFI_openness*umpqua, NCS_total*umpqua, TESQ_E_sum*umpqua, SRHI_healthy_minus_unhealthy*umpqua, RTFS_f1_minus_f2*umpqua, cancer_promoting_minus_preventing_FCI*umpqua, age365*umpqua, education_own*umpqua, household_income_per_person*umpqua, SST_PostErrorSlowW1_mean*umpqua, SST_mean_ssrt_0*umpqua, ROC_Crave_Regulate_Minus_Look*umpqua, ROC_Crave_Minus_Neutral*umpqua, WTP_unhealthy_minus_healthy*umpqua, wtp_liked_value_association-test_z_FDR_0.01*umpqua, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua, roc_reappraiseCrave_multivariate_regulation*umpqua, sst_CorrectGo_striatum_joint_mask*umpqua, sst_FailedStop_motor_control_striatum_joint_mask*umpqua, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua, Planning_aggregate*umpqua, Restraint_aggregate*umpqua, IMI_effort_importance_aggregate*umpqua, wtp_roc_koban_kober_craving_combined*umpqua, birthsex_factor_Male*umpqua, EDM*mckenzie, BIS_11*mckenzie, PCS*mckenzie, ACES_sum*mckenzie, BFI_agreeableness*mckenzie, BFI_conscientiousness*mckenzie, BFI_extraversion*mckenzie, BFI_neuroticism*mckenzie, BFI_openness*mckenzie, NCS_total*mckenzie, TESQ_E_sum*mckenzie, SRHI_healthy_minus_unhealthy*mckenzie, RTFS_f1_minus_f2*mckenzie, cancer_promoting_minus_preventing_FCI*mckenzie, age365*mckenzie, education_own*mckenzie, household_income_per_person*mckenzie, SST_PostErrorSlowW1_mean*mckenzie, SST_mean_ssrt_0*mckenzie, ROC_Crave_Regulate_Minus_Look*mckenzie, ROC_Crave_Minus_Neutral*mckenzie, WTP_unhealthy_minus_healthy*mckenzie, wtp_liked_value_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_multivariate_regulation*mckenzie, sst_CorrectGo_striatum_joint_mask*mckenzie, sst_FailedStop_motor_control_striatum_joint_mask*mckenzie, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie, Planning_aggregate*mckenzie, Restraint_aggregate*mckenzie, IMI_effort_importance_aggregate*mckenzie, wtp_roc_koban_kober_craving_combined*mckenzie, birthsex_factor_Male*mckenzie\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.get_predictor_data().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID, bf, NUTRIENT_RICH_FOODS_INDEX_2wkAverage, ANTINUTRIENT_DENSITY_2wkAverage, total_calorie\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.outcome_measures.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV022', 'DEV002', 'DEV280', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "run_real_analysis is True, so we're not randomizing the outcomes. \n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.36 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.37 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.36 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.38 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.38 seconds\n",
      "scores:\n",
      "[-0.016194228557085966, -0.015103737934053285, -0.09359689442769259, -2.3716258589656647e-05, -0.012552923902261925]\n",
      "overall_score:\n",
      "-0.027494300215936684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031106</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031106</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031148</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.031148</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031166</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031166</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031207</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031207</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031209</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.027862</td>\n",
       "      <td>0.018069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031209</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.027862</td>\n",
       "      <td>0.018069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031235</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.018176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031235</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.018176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.027940</td>\n",
       "      <td>0.017855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.027940</td>\n",
       "      <td>0.017855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>0.017680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>0.017680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.017684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.017684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031312</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.028043</td>\n",
       "      <td>0.017713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.031312</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.028043</td>\n",
       "      <td>0.017713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.027494300215936684}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'total_calorie', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTINUTRIENT_DENSITY_2wkAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV022', 'DEV002', 'DEV280', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "run_real_analysis is True, so we're not randomizing the outcomes. \n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.39 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.38 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.41 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_outcomes \u001b[39m=\u001b[39m icvm\u001b[39m.\u001b[39;49mdo_predictor_set_comparison(\n\u001b[1;32m      2\u001b[0m     predictor_sets, \u001b[39m'\u001b[39;49m\u001b[39mANTINUTRIENT_DENSITY_2wkAverage\u001b[39;49m\u001b[39m'\u001b[39;49m, dev_cv_analysis)\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/InterventionCVManager.py:87\u001b[0m, in \u001b[0;36mInterventionCVManager.do_predictor_set_comparison\u001b[0;34m(self, predictor_sets, outcome_var, mode)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m attempting to predict \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m outcome_var \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(predictor_set)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m predictors in the set \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m psk)\n\u001b[1;32m     86\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpredictors in that set are \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(predictor_set))\n\u001b[0;32m---> 87\u001b[0m     model_outcomes[psk] \u001b[39m=\u001b[39m devCVAnalysis\u001b[39m.\u001b[39;49mscore_and_present(\n\u001b[1;32m     88\u001b[0m         devCVAnalysis\u001b[39m.\u001b[39;49mget_active_predictor_subset(),\n\u001b[1;32m     89\u001b[0m         devCVAnalysis\u001b[39m.\u001b[39;49moutcome,\n\u001b[1;32m     90\u001b[0m         devCVAnalysis\u001b[39m.\u001b[39;49mgroup_assignments,\n\u001b[1;32m     91\u001b[0m         hyper_selection_function\u001b[39m=\u001b[39;49mhyper_func\n\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     94\u001b[0m \u001b[39m#get a dictionary of the overall scores for each model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m model_outcomes_comparison \u001b[39m=\u001b[39m { k:\n\u001b[1;32m     96\u001b[0m     model_outcomes[k][\u001b[39m'\u001b[39m\u001b[39moverall_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model_outcomes\u001b[39m.\u001b[39mkeys()}\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/DevCvAnalysis.py:267\u001b[0m, in \u001b[0;36mDevCvAnalysis.score_and_present\u001b[0;34m(self, predictor_data, outcome_measure, group_assignments, hyper_selection_function)\u001b[0m\n\u001b[1;32m    255\u001b[0m     hyper_selection_function\u001b[39m=\u001b[39mdo_hyperparameter_selection_loop\n\u001b[1;32m    257\u001b[0m \u001b[39m# if hyper_selection_function=='fast':\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m#     hyper_selection_function=do_hyperparameter_selection_loop_fast\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# elif hyper_selection_function=='main':\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m# outcome_measure = self.outcome\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m# group_assignments = self.group_assignment_onehots\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m scoring_data \u001b[39m=\u001b[39m do_scoring_loop(X\u001b[39m=\u001b[39;49mpredictor_data, y\u001b[39m=\u001b[39;49m outcome_measure, \n\u001b[1;32m    268\u001b[0m             groups \u001b[39m=\u001b[39;49m group_assignments, \n\u001b[1;32m    269\u001b[0m             hyperparameter_selection_on_fold\u001b[39m=\u001b[39;49mhyper_selection_function,\n\u001b[1;32m    270\u001b[0m             outer_folds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m    272\u001b[0m scores \u001b[39m=\u001b[39m scoring_data[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    273\u001b[0m best_models \u001b[39m=\u001b[39m scoring_data[\u001b[39m'\u001b[39m\u001b[39mbest_models\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:339\u001b[0m, in \u001b[0;36mdo_scoring_loop\u001b[0;34m(X, y, groups, hyperparameter_selection_on_fold, outer_folds)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39m#print(test_i_y)\u001b[39;00m\n\u001b[1;32m    337\u001b[0m inner_cv \u001b[39m=\u001b[39m IndependentVarStratifiedKFold(independent_vars\u001b[39m=\u001b[39mtrain_i_group_assignments, n_splits\u001b[39m=\u001b[39minner_splits, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m3211050\u001b[39m)\n\u001b[0;32m--> 339\u001b[0m selection_info \u001b[39m=\u001b[39m hyperparameter_selection_on_fold(train_i_X, train_i_y,cv \u001b[39m=\u001b[39;49m inner_cv)\n\u001b[1;32m    340\u001b[0m best_model_i \u001b[39m=\u001b[39m selection_info[\u001b[39m'\u001b[39m\u001b[39mbest_model\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    341\u001b[0m best_params_i \u001b[39m=\u001b[39m selection_info[\u001b[39m'\u001b[39m\u001b[39mbest_params_df\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:381\u001b[0m, in \u001b[0;36mdo_hyperparameter_selection_loop_fast\u001b[0;34m(X, y, cv)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_hyperparameter_selection_loop_fast\u001b[39m(X, y, cv):\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mreturn\u001b[39;00m(do_hyperparameter_selection_loop(X, y, cv, fast_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:519\u001b[0m, in \u001b[0;36mdo_hyperparameter_selection_loop\u001b[0;34m(X, y, cv, fast_mode)\u001b[0m\n\u001b[1;32m    515\u001b[0m gs_1 \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mpipeline, \n\u001b[1;32m    516\u001b[0m                     param_grid \u001b[39m=\u001b[39m full_param_grid, \n\u001b[1;32m    517\u001b[0m                     cv\u001b[39m=\u001b[39mcv,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    518\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 519\u001b[0m     gs_1\u001b[39m.\u001b[39;49mfit(X,y)\n\u001b[1;32m    520\u001b[0m     all_cv_results\u001b[39m.\u001b[39mappend(gs_1)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/svm/_base.py:192\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m     check_consistent_length(X, y)\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    196\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    197\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[1;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[1;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[1;32m    205\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/validation.py:1144\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1144\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m, estimator_name\u001b[39m=\u001b[39;49mestimator_name)\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n\u001b[1;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[39mwith\u001b[39;49;00m np\u001b[39m.\u001b[39;49merrstate(over\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m    122\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39;49m xp\u001b[39m.\u001b[39;49misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/core/_ufunc_config.py:435\u001b[0m, in \u001b[0;36merrstate.__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mexc_info):\n\u001b[0;32m--> 435\u001b[0m     seterr(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moldstate)\n\u001b[1;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _Unspecified:\n\u001b[1;32m    437\u001b[0m         seterrcall(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moldcall)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/core/_ufunc_config.py:127\u001b[0m, in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m    121\u001b[0m maskvalue \u001b[39m=\u001b[39m ((_errdict[divide] \u001b[39m<<\u001b[39m SHIFT_DIVIDEBYZERO) \u001b[39m+\u001b[39m\n\u001b[1;32m    122\u001b[0m              (_errdict[over] \u001b[39m<<\u001b[39m SHIFT_OVERFLOW) \u001b[39m+\u001b[39m\n\u001b[1;32m    123\u001b[0m              (_errdict[under] \u001b[39m<<\u001b[39m SHIFT_UNDERFLOW) \u001b[39m+\u001b[39m\n\u001b[1;32m    124\u001b[0m              (_errdict[invalid] \u001b[39m<<\u001b[39m SHIFT_INVALID))\n\u001b[1;32m    126\u001b[0m pyvals[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m maskvalue\n\u001b[0;32m--> 127\u001b[0m umath\u001b[39m.\u001b[39;49mseterrobj(pyvals)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m old\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'ANTINUTRIENT_DENSITY_2wkAverage', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUTRIENT_DENSITY_2wkAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV022', 'DEV002', 'DEV280', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "run_real_analysis is True, so we're not randomizing the outcomes. \n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_RICH_FOODS_INDEX_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.38 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.43 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.39 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.38 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.35 seconds\n",
      "scores:\n",
      "[0.06197247541590489, 0.0442508453875079, -0.06782816246411882, -0.0017427577356108337, 0.032773797721075915]\n",
      "overall_score:\n",
      "0.01388523966495181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.001753</td>\n",
       "      <td>0.032938</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.017393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.001753</td>\n",
       "      <td>0.032938</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.017393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.001820</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.017899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.001820</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.017899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.002859</td>\n",
       "      <td>0.033763</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.019102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.002859</td>\n",
       "      <td>0.033763</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.019102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.003176</td>\n",
       "      <td>0.034449</td>\n",
       "      <td>0.051186</td>\n",
       "      <td>0.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.003176</td>\n",
       "      <td>0.034449</td>\n",
       "      <td>0.051186</td>\n",
       "      <td>0.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.003201</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>0.050296</td>\n",
       "      <td>0.018665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 20, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.003201</td>\n",
       "      <td>0.033619</td>\n",
       "      <td>0.050296</td>\n",
       "      <td>0.018665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.003329</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>0.018786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.003329</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>0.018786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.003899</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.052203</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.003899</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.052203</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.046928</td>\n",
       "      <td>0.018763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.046928</td>\n",
       "      <td>0.018763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.004104</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.045054</td>\n",
       "      <td>0.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.004104</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.045054</td>\n",
       "      <td>0.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.004259</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.017150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.004259</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.017150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.048786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016656</td>\n",
       "      <td>0.016656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': 0.01388523966495181}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'NUTRIENT_RICH_FOODS_INDEX_2wkAverage', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Fat Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV022', 'DEV002', 'DEV280', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "run_real_analysis is True, so we're not randomizing the outcomes. \n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.35 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.34 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.35 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.34 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Ridge: 0.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Time elapsed for Lasso: 0.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.02, 1, 20]}\n",
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.02, 1, 20], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "Time elapsed for PolySVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17f695a80>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.02, 1, 20], 'estimator__gamma': [0.02, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Time elapsed for RBFSVR: 0.35 seconds\n",
      "scores:\n",
      "[0.043923411030694415, -0.03065496535973744, -0.00023669177823837373, -0.01817552415051038, -0.0050189984311515]\n",
      "overall_score:\n",
      "-0.002032553737788656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.040503</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.065812</td>\n",
       "      <td>0.034456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.040503</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.065812</td>\n",
       "      <td>0.034456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.043109</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.079270</td>\n",
       "      <td>0.037476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.043109</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.079270</td>\n",
       "      <td>0.037476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.043376</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.079597</td>\n",
       "      <td>0.037869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.043376</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.079597</td>\n",
       "      <td>0.037869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.044917</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.044915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.044917</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.044915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.045656</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.071369</td>\n",
       "      <td>0.049340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.045656</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.071369</td>\n",
       "      <td>0.049340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.046163</td>\n",
       "      <td>0.034079</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.045163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046163</td>\n",
       "      <td>0.034079</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.045163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046176</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.053939</td>\n",
       "      <td>0.048655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.02, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.046176</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.053939</td>\n",
       "      <td>0.048655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.046363</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.068228</td>\n",
       "      <td>0.046475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.046363</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.068228</td>\n",
       "      <td>0.046475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.02, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.046758</td>\n",
       "      <td>0.036768</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.02, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17f695a80&gt;}</th>\n",
       "      <td>-0.046758</td>\n",
       "      <td>0.036768</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.048193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>2.316367</td>\n",
       "      <td>0.041563</td>\n",
       "      <td>0.041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.139958</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.002032553737788656}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'NUTRIENT_DENSITY_2wkAverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive in to debug the analysis, let's try a statsmodel approach. We can use statsmodel to access the same data the ML is doing to see how it goes in identifying coefficients for umpqua, mckenzie, and willamette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>bf</th>\n",
       "      <th>NUTRIENT_DENSITY_2wkAverage</th>\n",
       "      <th>ANTINUTRIENT_DENSITY_2wkAverage</th>\n",
       "      <th>total_calorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV004</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV008</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>39.286168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5351.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>18.115014</td>\n",
       "      <td>12.426329</td>\n",
       "      <td>4098.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>15.260742</td>\n",
       "      <td>-2.335843</td>\n",
       "      <td>-4498.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.960706</td>\n",
       "      <td>-5.855379</td>\n",
       "      <td>-290.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42.269001</td>\n",
       "      <td>-2.790664</td>\n",
       "      <td>-4973.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-2.341372</td>\n",
       "      <td>-9.003925</td>\n",
       "      <td>-2371.082500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID   bf  NUTRIENT_DENSITY_2wkAverage  \\\n",
       "0    DEV004 -0.6                          NaN   \n",
       "1    DEV005  0.4                          NaN   \n",
       "2    DEV008 -1.1                          NaN   \n",
       "3    DEV009 -1.6                          NaN   \n",
       "4    DEV010  0.2                    39.286168   \n",
       "..      ...  ...                          ...   \n",
       "238  DEV308 -0.4                    18.115014   \n",
       "239  DEV309 -0.5                    15.260742   \n",
       "240  DEV310  0.1                    -1.960706   \n",
       "241  DEV311  0.5                    42.269001   \n",
       "242  DEV312 -7.5                    -2.341372   \n",
       "\n",
       "     ANTINUTRIENT_DENSITY_2wkAverage  total_calorie  \n",
       "0                                NaN            NaN  \n",
       "1                                NaN            NaN  \n",
       "2                                NaN            NaN  \n",
       "3                                NaN            NaN  \n",
       "4                                NaN    5351.104167  \n",
       "..                               ...            ...  \n",
       "238                        12.426329    4098.762500  \n",
       "239                        -2.335843   -4498.379167  \n",
       "240                        -5.855379    -290.115000  \n",
       "241                        -2.790664   -4973.492499  \n",
       "242                        -9.003925   -2371.082500  \n",
       "\n",
       "[243 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_cv_analysis.outcome_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the statsmodel package\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#do a statsmodel linear regression\n",
    "X_onehots_raw = dev_cv_analysis.group_assignment_onehots\n",
    "y_raw = dev_cv_analysis.outcome_measures['NUTRIENT_RICH_FOODS_INDEX_2wkAverage']\n",
    "na_mask = y_raw.isna() | X_onehots_raw.isna().any(axis=1)\n",
    "X_onehots = X_onehots_raw[~na_mask]\n",
    "y = y_raw[~na_mask]\n",
    "\n",
    "X_onehots.to_csv(dev_cv_analysis.dropbox_data_dir + \"/intervention_only_X_onehots.csv\")\n",
    "y.to_csv(dev_cv_analysis.dropbox_data_dir + \"/intervention_only_y.csv\")\n",
    "\n",
    "nutrient_density_ols_model = sm.OLS(y, X_onehots).fit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>NUTRIENT_RICH_FOODS_INDEX_2wkAverage</td> <th>  R-squared (uncentered):</th>      <td>   0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                             <td>OLS</td>                 <th>  Adj. R-squared (uncentered):</th> <td>   0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>Least Squares</td>            <th>  F-statistic:       </th>          <td>   13.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                       <td>Fri, 14 Jul 2023</td>           <th>  Prob (F-statistic):</th>          <td>2.80e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                           <td>17:24:08</td>               <th>  Log-Likelihood:    </th>          <td> -942.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>                <td>   220</td>                <th>  AIC:               </th>          <td>   1890.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                    <td>   218</td>                <th>  BIC:               </th>          <td>   1896.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                        <td>     2</td>                <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>                <td>nonrobust</td>              <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>umpqua</th>   <td>   11.0091</td> <td>    2.141</td> <td>    5.143</td> <td> 0.000</td> <td>    6.790</td> <td>   15.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mckenzie</th> <td>    1.6449</td> <td>    1.986</td> <td>    0.828</td> <td> 0.408</td> <td>   -2.270</td> <td>    5.559</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.470</td> <th>  Durbin-Watson:     </th> <td>   1.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.176</td> <th>  Jarque-Bera (JB):  </th> <td>   3.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.116</td> <th>  Prob(JB):          </th> <td>   0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.593</td> <th>  Cond. No.          </th> <td>    1.08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & NUTRIENT\\_RICH\\_FOODS\\_INDEX\\_2wkAverage & \\textbf{  R-squared (uncentered):}      &     0.111   \\\\\n",
       "\\textbf{Model:}            &                   OLS                    & \\textbf{  Adj. R-squared (uncentered):} &     0.103   \\\\\n",
       "\\textbf{Method:}           &              Least Squares               & \\textbf{  F-statistic:       }          &     13.57   \\\\\n",
       "\\textbf{Date:}             &             Fri, 14 Jul 2023             & \\textbf{  Prob (F-statistic):}          &  2.80e-06   \\\\\n",
       "\\textbf{Time:}             &                 17:24:08                 & \\textbf{  Log-Likelihood:    }          &   -942.77   \\\\\n",
       "\\textbf{No. Observations:} &                     220                  & \\textbf{  AIC:               }          &     1890.   \\\\\n",
       "\\textbf{Df Residuals:}     &                     218                  & \\textbf{  BIC:               }          &     1896.   \\\\\n",
       "\\textbf{Df Model:}         &                       2                  & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &                nonrobust                 & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{umpqua}   &      11.0091  &        2.141     &     5.143  &         0.000        &        6.790    &       15.228     \\\\\n",
       "\\textbf{mckenzie} &       1.6449  &        1.986     &     0.828  &         0.408        &       -2.270    &        5.559     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.470 & \\textbf{  Durbin-Watson:     } &    1.888  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.176 & \\textbf{  Jarque-Bera (JB):  } &    3.720  \\\\\n",
       "\\textbf{Skew:}          & -0.116 & \\textbf{  Prob(JB):          } &    0.156  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.593 & \\textbf{  Cond. No.          } &     1.08  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] RÂ² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                          OLS Regression Results                                         \n",
       "=========================================================================================================\n",
       "Dep. Variable:     NUTRIENT_RICH_FOODS_INDEX_2wkAverage   R-squared (uncentered):                   0.111\n",
       "Model:                                              OLS   Adj. R-squared (uncentered):              0.103\n",
       "Method:                                   Least Squares   F-statistic:                              13.57\n",
       "Date:                                  Fri, 14 Jul 2023   Prob (F-statistic):                    2.80e-06\n",
       "Time:                                          17:24:08   Log-Likelihood:                         -942.77\n",
       "No. Observations:                                   220   AIC:                                      1890.\n",
       "Df Residuals:                                       218   BIC:                                      1896.\n",
       "Df Model:                                             2                                                  \n",
       "Covariance Type:                              nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "umpqua        11.0091      2.141      5.143      0.000       6.790      15.228\n",
       "mckenzie       1.6449      1.986      0.828      0.408      -2.270       5.559\n",
       "==============================================================================\n",
       "Omnibus:                        3.470   Durbin-Watson:                   1.888\n",
       "Prob(Omnibus):                  0.176   Jarque-Bera (JB):                3.720\n",
       "Skew:                          -0.116   Prob(JB):                        0.156\n",
       "Kurtosis:                       3.593   Cond. No.                         1.08\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrient_density_ols_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the model in R, the t-score and p-value are almost identical, but the R-squared and adjusted r-squared look pretty different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>NUTRIENT_RICH_FOODS_INDEX_2wkAverage</td> <th>  R-squared:         </th> <td>   0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                             <td>OLS</td>                 <th>  Adj. R-squared:    </th> <td>   0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                       <td>Least Squares</td>            <th>  F-statistic:       </th> <td>   5.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                       <td>Fri, 14 Jul 2023</td>           <th>  Prob (F-statistic):</th>  <td>0.00345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                           <td>17:24:11</td>               <th>  Log-Likelihood:    </th> <td> -941.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>                <td>   220</td>                <th>  AIC:               </th> <td>   1889.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                    <td>   217</td>                <th>  BIC:               </th> <td>   1899.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                        <td>     2</td>                <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>                <td>nonrobust</td>              <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    3.1090</td> <td>    2.060</td> <td>    1.509</td> <td> 0.133</td> <td>   -0.951</td> <td>    7.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>umpqua</th>   <td>    7.9000</td> <td>    2.967</td> <td>    2.663</td> <td> 0.008</td> <td>    2.053</td> <td>   13.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mckenzie</th> <td>   -1.4641</td> <td>    2.858</td> <td>   -0.512</td> <td> 0.609</td> <td>   -7.096</td> <td>    4.168</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.402</td> <th>  Durbin-Watson:     </th> <td>   1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.183</td> <th>  Jarque-Bera (JB):  </th> <td>   3.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.085</td> <th>  Prob(JB):          </th> <td>   0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.618</td> <th>  Cond. No.          </th> <td>    3.75</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & NUTRIENT\\_RICH\\_FOODS\\_INDEX\\_2wkAverage & \\textbf{  R-squared:         } &     0.051   \\\\\n",
       "\\textbf{Model:}            &                   OLS                    & \\textbf{  Adj. R-squared:    } &     0.042   \\\\\n",
       "\\textbf{Method:}           &              Least Squares               & \\textbf{  F-statistic:       } &     5.819   \\\\\n",
       "\\textbf{Date:}             &             Fri, 14 Jul 2023             & \\textbf{  Prob (F-statistic):} &  0.00345    \\\\\n",
       "\\textbf{Time:}             &                 17:24:11                 & \\textbf{  Log-Likelihood:    } &   -941.62   \\\\\n",
       "\\textbf{No. Observations:} &                     220                  & \\textbf{  AIC:               } &     1889.   \\\\\n",
       "\\textbf{Df Residuals:}     &                     217                  & \\textbf{  BIC:               } &     1899.   \\\\\n",
       "\\textbf{Df Model:}         &                       2                  & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &                nonrobust                 & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}    &       3.1090  &        2.060     &     1.509  &         0.133        &       -0.951    &        7.169     \\\\\n",
       "\\textbf{umpqua}   &       7.9000  &        2.967     &     2.663  &         0.008        &        2.053    &       13.747     \\\\\n",
       "\\textbf{mckenzie} &      -1.4641  &        2.858     &    -0.512  &         0.609        &       -7.096    &        4.168     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.402 & \\textbf{  Durbin-Watson:     } &    1.881  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.183 & \\textbf{  Jarque-Bera (JB):  } &    3.768  \\\\\n",
       "\\textbf{Skew:}          & -0.085 & \\textbf{  Prob(JB):          } &    0.152  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.618 & \\textbf{  Cond. No.          } &     3.75  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                     OLS Regression Results                                     \n",
       "================================================================================================\n",
       "Dep. Variable:     NUTRIENT_RICH_FOODS_INDEX_2wkAverage   R-squared:                       0.051\n",
       "Model:                                              OLS   Adj. R-squared:                  0.042\n",
       "Method:                                   Least Squares   F-statistic:                     5.819\n",
       "Date:                                  Fri, 14 Jul 2023   Prob (F-statistic):            0.00345\n",
       "Time:                                          17:24:11   Log-Likelihood:                -941.62\n",
       "No. Observations:                                   220   AIC:                             1889.\n",
       "Df Residuals:                                       217   BIC:                             1899.\n",
       "Df Model:                                             2                                         \n",
       "Covariance Type:                              nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.1090      2.060      1.509      0.133      -0.951       7.169\n",
       "umpqua         7.9000      2.967      2.663      0.008       2.053      13.747\n",
       "mckenzie      -1.4641      2.858     -0.512      0.609      -7.096       4.168\n",
       "==============================================================================\n",
       "Omnibus:                        3.402   Durbin-Watson:                   1.881\n",
       "Prob(Omnibus):                  0.183   Jarque-Bera (JB):                3.768\n",
       "Skew:                          -0.085   Prob(JB):                        0.152\n",
       "Kurtosis:                       3.618   Cond. No.                         3.75\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add a constant to the model\n",
    "X_onehots_w_const = sm.add_constant(X_onehots)\n",
    "nutrient_density_ols_model = sm.OLS(y, X_onehots_w_const).fit()\n",
    "nutrient_density_ols_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm--with a constant, the effect just about disappears. That's really odd, because we'd expect the constant to behave like the constant in R's lm function.\n",
    "\n",
    "Do we have the same dataset? small differences in the dataset can make a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_na_masked = dev_cv_analysis.outcome_measures[~na_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>bf</th>\n",
       "      <th>NUTRIENT_DENSITY_2wkAverage</th>\n",
       "      <th>ANTINUTRIENT_DENSITY_2wkAverage</th>\n",
       "      <th>total_calorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>39.286168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5351.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEV011</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>19.513277</td>\n",
       "      <td>-17.041968</td>\n",
       "      <td>-4748.649166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEV012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.317783</td>\n",
       "      <td>8.130856</td>\n",
       "      <td>-1419.556666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEV014</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>19.641489</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>-2743.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEV015</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.616559</td>\n",
       "      <td>0.354070</td>\n",
       "      <td>1683.897500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>18.115014</td>\n",
       "      <td>12.426329</td>\n",
       "      <td>4098.762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>15.260742</td>\n",
       "      <td>-2.335843</td>\n",
       "      <td>-4498.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.960706</td>\n",
       "      <td>-5.855379</td>\n",
       "      <td>-290.115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42.269001</td>\n",
       "      <td>-2.790664</td>\n",
       "      <td>-4973.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-2.341372</td>\n",
       "      <td>-9.003925</td>\n",
       "      <td>-2371.082500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID   bf  NUTRIENT_DENSITY_2wkAverage  \\\n",
       "4    DEV010  0.2                    39.286168   \n",
       "5    DEV011 -0.8                    19.513277   \n",
       "6    DEV012  0.5                     7.317783   \n",
       "8    DEV014 -2.3                    19.641489   \n",
       "9    DEV015  0.5                     7.616559   \n",
       "..      ...  ...                          ...   \n",
       "238  DEV308 -0.4                    18.115014   \n",
       "239  DEV309 -0.5                    15.260742   \n",
       "240  DEV310  0.1                    -1.960706   \n",
       "241  DEV311  0.5                    42.269001   \n",
       "242  DEV312 -7.5                    -2.341372   \n",
       "\n",
       "     ANTINUTRIENT_DENSITY_2wkAverage  total_calorie  \n",
       "4                                NaN    5351.104167  \n",
       "5                         -17.041968   -4748.649166  \n",
       "6                           8.130856   -1419.556666  \n",
       "8                           0.990242   -2743.742500  \n",
       "9                           0.354070    1683.897500  \n",
       "..                               ...            ...  \n",
       "238                        12.426329    4098.762500  \n",
       "239                        -2.335843   -4498.379167  \n",
       "240                        -5.855379    -290.115000  \n",
       "241                        -2.790664   -4973.492499  \n",
       "242                        -9.003925   -2371.082500  \n",
       "\n",
       "[220 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_na_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEV010, DEV011, DEV012, DEV014, DEV015, DEV016, DEV017, DEV018, DEV020, DEV021, DEV023, DEV024, DEV025, DEV026, DEV027, DEV028, DEV029, DEV030, DEV031, DEV033, DEV035, DEV036, DEV038, DEV039, DEV040, DEV041, DEV042, DEV043, DEV044, DEV046, DEV047, DEV048, DEV049, DEV050, DEV051, DEV052, DEV053, DEV054, DEV055, DEV056, DEV057, DEV058, DEV059, DEV060, DEV061, DEV062, DEV063, DEV064, DEV065, DEV066, DEV067, DEV068, DEV069, DEV070, DEV071, DEV072, DEV073, DEV074, DEV075, DEV076, DEV077, DEV078, DEV079, DEV083, DEV084, DEV085, DEV086, DEV087, DEV088, DEV089, DEV090, DEV091, DEV093, DEV094, DEV096, DEV097, DEV098, DEV099, DEV100, DEV101, DEV102, DEV103, DEV104, DEV107, DEV108, DEV109, DEV110, DEV112, DEV113, DEV115, DEV116, DEV117, DEV118, DEV119, DEV120, DEV121, DEV122, DEV125, DEV126, DEV127, DEV128, DEV129, DEV130, DEV132, DEV133, DEV134, DEV135, DEV137, DEV138, DEV139, DEV140, DEV141, DEV143, DEV144, DEV145, DEV147, DEV149, DEV151, DEV153, DEV155, DEV156, DEV157, DEV158, DEV159, DEV161, DEV163, DEV164, DEV167, DEV178, DEV179, DEV181, DEV182, DEV185, DEV186, DEV187, DEV191, DEV195, DEV196, DEV197, DEV199, DEV200, DEV203, DEV205, DEV206, DEV207, DEV208, DEV209, DEV211, DEV215, DEV216, DEV217, DEV220, DEV222, DEV223, DEV230, DEV231, DEV232, DEV233, DEV235, DEV236, DEV237, DEV238, DEV239, DEV240, DEV241, DEV243, DEV244, DEV246, DEV247, DEV249, DEV250, DEV251, DEV254, DEV255, DEV256, DEV257, DEV258, DEV259, DEV260, DEV261, DEV262, DEV263, DEV264, DEV265, DEV267, DEV268, DEV269, DEV271, DEV272, DEV273, DEV274, DEV275, DEV276, DEV277, DEV281, DEV282, DEV283, DEV284, DEV286, DEV291, DEV292, DEV294, DEV295, DEV296, DEV297, DEV298, DEV299, DEV300, DEV301, DEV302, DEV303, DEV304, DEV305, DEV306, DEV307, DEV308, DEV309, DEV310, DEV311, DEV312'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(outcomes_na_masked.SID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>NUTRIENT_DENSITY_2wkAverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>39.286168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEV011</td>\n",
       "      <td>19.513277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEV012</td>\n",
       "      <td>7.317783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEV014</td>\n",
       "      <td>19.641489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEV015</td>\n",
       "      <td>7.616559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>18.115014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>15.260742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>-1.960706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>42.269001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>-2.341372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID  NUTRIENT_DENSITY_2wkAverage\n",
       "4    DEV010                    39.286168\n",
       "5    DEV011                    19.513277\n",
       "6    DEV012                     7.317783\n",
       "8    DEV014                    19.641489\n",
       "9    DEV015                     7.616559\n",
       "..      ...                          ...\n",
       "238  DEV308                    18.115014\n",
       "239  DEV309                    15.260742\n",
       "240  DEV310                    -1.960706\n",
       "241  DEV311                    42.269001\n",
       "242  DEV312                    -2.341372\n",
       "\n",
       "[220 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_na_masked.loc[:,['SID','NUTRIENT_DENSITY_2wkAverage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_by_wave_ppt = pd.read_csv(dev_cv_analysis.data_by_wave_ppt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply standardscaler to the y variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y_scaled = scaler.fit_transform(y.values.reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   5.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 14 Jul 2023</td> <th>  Prob (F-statistic):</th>           <td>0.00519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:25:00</td>     <th>  Log-Likelihood:    </th>          <td> -306.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   220</td>      <th>  AIC:               </th>          <td>   617.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   218</td>      <th>  BIC:               </th>          <td>   624.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>umpqua</th>   <td>    0.3335</td> <td>    0.119</td> <td>    2.804</td> <td> 0.005</td> <td>    0.099</td> <td>    0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mckenzie</th> <td>   -0.1884</td> <td>    0.110</td> <td>   -1.707</td> <td> 0.089</td> <td>   -0.406</td> <td>    0.029</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.304</td> <th>  Durbin-Watson:     </th> <td>   1.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.192</td> <th>  Jarque-Bera (JB):  </th> <td>   3.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.065</td> <th>  Prob(JB):          </th> <td>   0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.621</td> <th>  Cond. No.          </th> <td>    1.08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared (uncentered):}      &     0.047   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.038   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     5.390   \\\\\n",
       "\\textbf{Date:}             & Fri, 14 Jul 2023 & \\textbf{  Prob (F-statistic):}          &  0.00519    \\\\\n",
       "\\textbf{Time:}             &     17:25:00     & \\textbf{  Log-Likelihood:    }          &   -306.86   \\\\\n",
       "\\textbf{No. Observations:} &         220      & \\textbf{  AIC:               }          &     617.7   \\\\\n",
       "\\textbf{Df Residuals:}     &         218      & \\textbf{  BIC:               }          &     624.5   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{umpqua}   &       0.3335  &        0.119     &     2.804  &         0.005        &        0.099    &        0.568     \\\\\n",
       "\\textbf{mckenzie} &      -0.1884  &        0.110     &    -1.707  &         0.089        &       -0.406    &        0.029     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.304 & \\textbf{  Durbin-Watson:     } &    1.873  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.192 & \\textbf{  Jarque-Bera (JB):  } &    3.690  \\\\\n",
       "\\textbf{Skew:}          & -0.065 & \\textbf{  Prob(JB):          } &    0.158  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.621 & \\textbf{  Cond. No.          } &     1.08  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] RÂ² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.047\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.038\n",
       "Method:                 Least Squares   F-statistic:                              5.390\n",
       "Date:                Fri, 14 Jul 2023   Prob (F-statistic):                     0.00519\n",
       "Time:                        17:25:00   Log-Likelihood:                         -306.86\n",
       "No. Observations:                 220   AIC:                                      617.7\n",
       "Df Residuals:                     218   BIC:                                      624.5\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "umpqua         0.3335      0.119      2.804      0.005       0.099       0.568\n",
       "mckenzie      -0.1884      0.110     -1.707      0.089      -0.406       0.029\n",
       "==============================================================================\n",
       "Omnibus:                        3.304   Durbin-Watson:                   1.873\n",
       "Prob(Omnibus):                  0.192   Jarque-Bera (JB):                3.690\n",
       "Skew:                          -0.065   Prob(JB):                        0.158\n",
       "Kurtosis:                       3.621   Cond. No.                         1.08\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add a constant to the model\n",
    "nutrient_density_ols_model = sm.OLS(y_scaled, X_onehots).fit()\n",
    "nutrient_density_ols_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all interesting, but Ridge and Lasso both add an intercept by default, so we don't need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
