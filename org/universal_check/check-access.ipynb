{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal DEV data check\n",
    "\n",
    "This file is designed to access all data sources and cross-reference to see where data is missing.\n",
    "\n",
    "We should be able to do this locally (in order to access the Dropbox, which is inaccessible on talapas) and FTP to talapas to grab talapas stuff."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talapas FTP\n",
    "\n",
    "Let's set up the talapas FTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysftp\n",
    "import paramiko\n",
    "#not sure if this will really continue to wokr without an explicit reference to a key file but let's see!\n",
    "pagent = paramiko.agent.Agent()\n",
    "srv = pysftp.Connection(host=\"talapas-ln2.uoregon.edu\", username=\"bsmith16\", private_key=pagent.get_keys()[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths for accessing from local machine\n",
    "redcap_csv_path= '../dicom_check/DEV-Sessions_DATA_2022-10-19_2234.csv'\n",
    "behavioral_data_sst_all_csv = '~/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/sst_behavioral_data_all_20230119.csv'\n",
    "self_report_behav_summary_data = '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/data_by_ppt.csv'\n",
    "\n",
    "#absolute paths for accessing directly from talapas\n",
    "fmriprep_server_path = '/gpfs/projects/sanlab/shared/DEV/bids_data/derivatives/fmriprep'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load items\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### DICOMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#regex filter the directory \n",
    "\n",
    "dicom_dev_regex = 'DEV\\d\\d\\d\\_'\n",
    "raw_dicom_folder_list = srv.listdir('/gpfs/projects/lcni/dcm/sanlab/Berkman/DEV/')\n",
    "raw_dicom_dev_folder_list = [x for x in raw_dicom_folder_list if re.search(dicom_dev_regex, x)]\n",
    "non_dev_folders =  [x for x in raw_dicom_folder_list if not re.search(dicom_dev_regex, x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['159_20200126_115140',\n",
       " 'DEV0903_20190607_090700',\n",
       " 'DEV310`_20220911_120849',\n",
       " 'DEV_20171214',\n",
       " 'DEV_20210608_170401',\n",
       " 'DEV_20210714_173417',\n",
       " 'Matlabtest_20191023_154406',\n",
       " 'Phantom^of the opera_20180430_110701',\n",
       " 'TEST999_20180219_170145',\n",
       " 'dev125_20190823_102411',\n",
       " 'dev133_20190808_171200',\n",
       " 'matlabtest2_20191025_121247',\n",
       " 'phantom_20181211_112538',\n",
       " 'test dev_20180219_155612',\n",
       " 'wwe_20180131_135555']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_dev_folders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a bunch of incorrectly named DICOM files here that we'll need to go through. We arleady have a process for this in `DEV_scripts/org/dicom_check/` so need to follow that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can skip forward to the fMRIPrep data and register what is missing there vs. the REDCAP data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIDS data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of the participants with BIDS folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_folder_all = srv.listdir('/gpfs/projects/sanlab/shared/DEV/bids_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_folder_regex = 'sub-DEV\\d\\d\\d'\n",
    "bids_participants = [x for x in bids_folder_all if re.search(bids_folder_regex, x)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRIPrep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRIPrep_folder_all = srv.listdir(fmriprep_server_path)\n",
    "fmriprep_folder_regex = 'sub-DEV\\d\\d\\d$'\n",
    "fmriprep_folder_list = [x for x in fMRIPrep_folder_all if re.search(fmriprep_folder_regex, x)]\n",
    "\n",
    "#now get a list of fMRIPrep sessions\n",
    "fmri_prep_session_df = pd.DataFrame(columns=['fmriprep_subj_folder', 'fmriprep_session_folder'])\n",
    "for fmriprep_subj_folder in fmriprep_folder_list:\n",
    "    fmriprep_subj_path = fmriprep_server_path + '/' + fmriprep_subj_folder\n",
    "    fmriprep_subj_dirlist = srv.listdir(fmriprep_subj_path)\n",
    "    fmri_prep_session_list = [x for x in fmriprep_subj_dirlist if re.search('ses-wave\\d+', x)]\n",
    "    for fmriprep_session_folder in fmri_prep_session_list:\n",
    "        fmri_prep_session_df = pd.concat([fmri_prep_session_df,pd.DataFrame({'fmriprep_subj_folder': [fmriprep_subj_folder], 'fmriprep_session_folder': [fmriprep_session_folder]})], ignore_index=True)\n",
    "    #print(fmriprep_subj_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redcap session list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_sessions_list = pd.read_csv(redcap_csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_behav_summary_df = pd.read_csv(self_report_behav_summary_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That isn't quite the right file, because it only has data for the first wave, and we need to, at this point, get data for all waves. So let's put aside cross-referencing behavioral data until we decide how to do that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the redcap list for matching\n",
    "redcap_sessions_list['redcap_wave'] = redcap_sessions_list['redcap_event_name'].str.extract('session_(\\d+)')[0]\n",
    "#rename dev_id to redcap_dev_id\n",
    "redcap_sessions_list.rename(columns={'dev_id': 'redcap_dev_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the fmriprep list for matching\n",
    "\n",
    "fmri_prep_session_df['fmriprep_dev_id'] = fmri_prep_session_df['fmriprep_subj_folder'].str.extract('sub-(DEV\\d\\d\\d)')[0]\n",
    "fmri_prep_session_df['fmriprep_wave'] = fmri_prep_session_df['fmriprep_session_folder'].str.extract('ses-wave(\\d+)')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_list_1 = pd.merge(redcap_sessions_list,fmri_prep_session_df, how='outer', \n",
    "    left_on=['redcap_dev_id', 'redcap_wave'],\n",
    "    right_on=['fmriprep_dev_id', 'fmriprep_wave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_list_1.to_csv('match_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-reference DEV QC and Exclusions with Redcap to get a new list of DEV subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gspread' from 'pydrive2.drive' (/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pydrive2/drive.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydrive2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauth\u001b[39;00m \u001b[39mimport\u001b[39;00m GoogleAuth\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydrive2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdrive\u001b[39;00m \u001b[39mimport\u001b[39;00m GoogleDrive\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydrive2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdrive\u001b[39;00m \u001b[39mimport\u001b[39;00m gspread\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gspread' from 'pydrive2.drive' (/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pydrive2/drive.py)"
     ]
    }
   ],
   "source": [
    "# access a public google sheet with teh googlesheets api\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=435162197765-u17g2s1q1mac7fsulm6ebbb79s1tq4hm.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&access_type=offline&response_type=code\n",
      "\n",
      "If your browser is on a different machine then exit and re-run this\n",
      "application with the command-line parameter\n",
      "\n",
      "  --noauth_local_webserver\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "#access a google sheet from python\n",
    "from gsheets import Sheets\n",
    "sheets = Sheets.from_files('~/.ssh/client_secret.json', '~/.ssh/storage.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "909277993f62fb7e20ac69fcf44bdd9b081a442143999a07060a8e8285960539"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
